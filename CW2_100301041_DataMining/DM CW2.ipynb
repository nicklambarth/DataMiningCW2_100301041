{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data csv\n",
    "#data = pd.read_csv('LoanStats_2017Q2.csv')\n",
    "#a data error was thrown when attempting to read in the full dataset\n",
    "data = pd.read_csv('data_31stmarch.csv')\n",
    "d_count = data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected file size is correct\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert data.loan_amnt.count() == 50000\n",
    "    print(\"Expected file size is correct\")\n",
    "except:\n",
    "    print(\"Incorrect file size\")\n",
    "#checking the correct number of rows were read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt        term int_rate grade emp_length home_ownership  annual_inc  \\\n",
      "0      16000   60 months   12.62%     C  10+ years       MORTGAGE     94000.0   \n",
      "1       8000   36 months   14.08%     C    9 years           RENT    120000.0   \n",
      "2      26000   36 months    9.93%     B    7 years            OWN     57900.0   \n",
      "3      18950   60 months   21.45%     D     1 year       MORTGAGE    130000.0   \n",
      "4       9600   36 months    7.97%     A   < 1 year            OWN    140000.0   \n",
      "\n",
      "              purpose    dti  delinq_2yrs  ...  num_tl_op_past_12m  \\\n",
      "0  debt_consolidation  25.61            0  ...                   3   \n",
      "1            vacation  31.58            0  ...                   0   \n",
      "2    home_improvement  12.19            0  ...                   0   \n",
      "3         credit_card  31.39            0  ...                   1   \n",
      "4         credit_card  18.34            0  ...                   2   \n",
      "\n",
      "   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies tax_liens  \\\n",
      "0           100.0             100.0                     0         0   \n",
      "1           100.0             100.0                     0         0   \n",
      "2           100.0              60.0                     0         1   \n",
      "3            88.0             100.0                     0         0   \n",
      "4            93.2              28.6                     0         0   \n",
      "\n",
      "   tot_hi_cred_lim  total_bal_ex_mort  total_bc_limit  \\\n",
      "0           319900              44830            2400   \n",
      "1           133955              87827           27300   \n",
      "2            89700              41031           55300   \n",
      "3          1401945             109236           73600   \n",
      "4           391409             278895           18900   \n",
      "\n",
      "   total_il_high_credit_limit  loan_status  \n",
      "0                       16000      Current  \n",
      "1                       91655      Current  \n",
      "2                       34400      Current  \n",
      "3                       40664      Current  \n",
      "4                      297759      Current  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#dropping member_id as all rows were empty\n",
    "data = data.drop(columns = ['member_id']) \n",
    "#dropping all columns that are too logically similar.\n",
    "data = data.drop(columns = ['funded_amnt', 'funded_amnt_inv', 'installment'])\n",
    "#too similar to loan_amnt\n",
    "data = data.drop(columns = ['total_pymnt_inv', 'collection_recovery_fee','sub_grade', 'open_il_12m', 'out_prncp_inv'])\n",
    "#dropping columns with greater than 60% of data missing or nan\n",
    "data = data.dropna(thresh = data.shape[0]*0.6, how='all',axis=1)\n",
    "#dropping other columns that are not necessary, want to make the model as \"light\" as possible\n",
    "data = data.drop(columns = ['issue_d', 'addr_state','pymnt_plan','verification_status', 'last_credit_pull_d','initial_list_status'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#filling emp_length nan with 0 (as no employment length must mean 0 years in employment)\n",
    "data.emp_length = data.emp_length.fillna(0)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding all categorical columns so that they can be utilised for classification\n",
    "data_home_ownership_onehot = pd.get_dummies(data.home_ownership, prefix='home_ownership')\n",
    "#print(data_home_ownership_onehot.head())\n",
    "data_grade_onehot = pd.get_dummies(data.grade, prefix ='grade')\n",
    "data_application_type_onehot = pd.get_dummies(data.application_type, prefix = 'application_type')\n",
    "data = data.join([data_home_ownership_onehot, data_grade_onehot, data_application_type_onehot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing loan_status strings with integers (Current = 0, Fully Paid = 1, Late(16-30 days) = 2, Late(31-120 days) = 3)\n",
    "data.loan_status = data.loan_status.replace(['Current','Fully Paid', 'Late(16-30 days)', 'Late(31-120 days)'], ['0','1','2','3'])\n",
    "#loan status set to be either late(1) or not(0)\n",
    "data.loan_status = data.loan_status.replace(['0','1'], '0')\n",
    "data.loan_status = data.loan_status.replace(['2','3'], '1')\n",
    "#print(data.loan_status)\n",
    "#This data can now be used as labels for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripping non-number values from cells\n",
    "#removing 'months' from the term column to just give an int\n",
    "data.term = data.term.str.replace(r'\\D+', '')\n",
    "#removing years, +, < from emp_length\n",
    "data.emp_length = data.emp_length.str.replace(r'\\D+', '')\n",
    "#filling nan in emp_length with 0\n",
    "data.emp_length = data.emp_length.fillna(0)\n",
    "#trimming % symbols from int_rate and revol_util\n",
    "data.int_rate = data.int_rate.str.replace(r'%', '')\n",
    "data.revol_util = data.revol_util.str.replace(r'%', '')\n",
    "#print(data.revol_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the labels for training_data\n",
    "labels = data.loan_status\n",
    "#print(labels_indiv)\n",
    "#dropping categorical features\n",
    "training_data = data.drop(columns = ['home_ownership','purpose', 'application_type', 'loan_status', 'grade'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#attempting to build a \"light\" model - processing data \n",
    "\n",
    "light_data = data.copy()\n",
    "light_data = light_data.loc[:, ['loan_amnt', 'term', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'pub_rec', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'pub_rec_bankruptcies', 'loan_status', 'home_ownership_ANY','home_ownership_MORTGAGE', \n",
    "        'home_ownership_NONE', 'home_ownership_OWN','home_ownership_RENT', \n",
    "        'grade_A', 'grade_B', 'grade_C', 'grade_D',\n",
    "       'grade_E', 'grade_F', 'grade_G', 'application_type_ ',\n",
    "       'application_type_DIRECT_PAY', 'application_type_INDIVIDUAL',\n",
    "       'application_type_JOINT']]\n",
    "\n",
    "light_data_labels = light_data.loan_status\n",
    "light_data = light_data.drop(columns = ['loan_status'])\n",
    "\n",
    "#using the best split stated earlier - 60% training data\n",
    "light_train_data, light_test_data, light_train_labels, light_test_labels = train_test_split(light_data, light_data_labels, train_size = 0.6, random_state = 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a train_test_split so that validation can be done after training.\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(training_data, labels, train_size = 0.8, random_state = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.08825492858887 seconds\n"
     ]
    }
   ],
   "source": [
    "#defining and training classifier\n",
    "import time\n",
    "\n",
    "start_1_train = time.time()\n",
    "classifier_1 = SVC(probability=True)\n",
    "classifier_1.fit(train_data, train_labels)\n",
    "run_time_1_train = time.time() - start_1_train\n",
    "print(\"train time:\", run_time_1_train, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy with an rbf kernel: 0.9954439607168168\n",
      "0.9587931632995605 seconds\n"
     ]
    }
   ],
   "source": [
    "#classifier accuracy for the data_set (rbf kernel)\n",
    "start_1_test = time.time()\n",
    "print(\"Classification accuracy with an rbf kernel:\", classifier_1.score(test_data, test_labels))\n",
    "run_time_1_test = time.time() - start_1_test\n",
    "print(run_time_1_test, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 96.0947778224945 seconds\n",
      "Classification accuracy with a poly kernel 0.9954439607168168\n",
      "0.2574799060821533 seconds\n"
     ]
    }
   ],
   "source": [
    "#creating and training classifier with a poly kernel\n",
    "start_2_train = time.time()\n",
    "classifier_2 = SVC(kernel = 'poly')\n",
    "classifier_2.fit(train_data, train_labels)\n",
    "run_time_2_train = time.time() - start_2_train\n",
    "print(\"train time:\", run_time_2_train, \"seconds\")\n",
    "#classifier accuracy for a poly kernel\n",
    "start_2_test = time.time()\n",
    "print(\"Classification accuracy with a poly kernel\", classifier_2.score(test_data, test_labels))\n",
    "run_time_2_test = time.time() - start_2_test\n",
    "print(run_time_2_test, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating and training classifier with a linear kernel\n",
    "start_3_train = time.time()\n",
    "classifier_3 = SVC(kernel = 'linear')\n",
    "classifier_3.fit(train_data, train_labels)\n",
    "run_time_3_train = time.time() - start_3_train\n",
    "print(\"train time:\", run_time_3_train, \"seconds\")\n",
    "#classifier accuracy for a linear kernel\n",
    "start_3_test = time.time()\n",
    "print(\"Classification accuracy with a linear kernel\", classifier_3.score(test_data, test_labels))\n",
    "run_time_3_test = time.time() - start_3_test\n",
    "print(run_time_3_test, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 2.4102752208709717 seconds\n",
      "F1 score for classifier 1 (rbf kernel): 0.9958689400996315\n",
      "Precision score for classifier 1 (rbf kernel): 0.9958689400996315\n",
      "Recall score for classifier 1 (rbf kernel): 0.9958689400996315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "#only test data and labels will be used, train_test_split called to get a random selection.\n",
    "filler_train, metrics_test_data, filler_labels, metrics_test_labels = train_test_split(training_data, labels, train_size = 0.5, random_state = 46)\n",
    "\n",
    "#getting these metrics for classifer 1 (rbf)\n",
    "start_1_predict = time.time()\n",
    "predicted_labels_1 = classifier_1.predict(metrics_test_data)\n",
    "run_time_1_predict = time.time() - start_1_predict\n",
    "print(\"Prediction time:\", run_time_1_predict, \"seconds\")\n",
    "\n",
    "f1_classifier_1 = f1_score(metrics_test_labels, predicted_labels_1, average = 'micro')\n",
    "precision_classifier_1 = precision_score(metrics_test_labels, predicted_labels_1, average = 'micro')\n",
    "recall_classifier_1 = recall_score(metrics_test_labels, predicted_labels_1, average = 'micro')\n",
    "\n",
    "print(\"F1 score for classifier 1 (rbf kernel):\", f1_classifier_1)\n",
    "print(\"Precision score for classifier 1 (rbf kernel):\", precision_classifier_1)\n",
    "print(\"Recall score for classifier 1 (rbf kernel):\", recall_classifier_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.6435251235961914 seconds\n",
      "F1 score for classifier 2 (poly kernel): 0.9958689400996315\n",
      "Precision score for classifier 2 (poly kernel): 0.9958689400996315\n",
      "Recall score for classifier 2 (poly kernel): 0.9958689400996315\n"
     ]
    }
   ],
   "source": [
    "#getting metrics imported above for classifier 2 (poly)\n",
    "start_2_predict = time.time()\n",
    "predicted_labels_2 = classifier_2.predict(metrics_test_data)\n",
    "run_time_2_predict = time.time() - start_2_predict\n",
    "print(\"Prediction time:\", run_time_2_predict, \"seconds\")\n",
    "\n",
    "f1_classifier_2 = f1_score(metrics_test_labels, predicted_labels_2, average = 'micro')\n",
    "precision_classifier_2 = precision_score(metrics_test_labels, predicted_labels_2, average = 'micro')\n",
    "recall_classifier_2 = recall_score(metrics_test_labels, predicted_labels_2, average = 'micro')\n",
    "\n",
    "print(\"F1 score for classifier 2 (poly kernel):\", f1_classifier_2)\n",
    "print(\"Precision score for classifier 2 (poly kernel):\", precision_classifier_2)\n",
    "print(\"Recall score for classifier 2 (poly kernel):\", recall_classifier_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting metrics imported above for classifier 3 (linear)\n",
    "start_3_predict = time.time()\n",
    "predicted_labels_3 = classifier_3.predict(metrics_test_data)\n",
    "run_time_3_predict = time.time() - start_3_predict\n",
    "print(\"Prediction time:\", run_time_3_predict, \"seconds\")\n",
    "\n",
    "f1_classifier_3 = f1_score(metrics_test_labels, predicted_labels_3, average = 'micro')\n",
    "precision_classifier_3 = precision_score(metrics_test_labels, predicted_labels_3, average = 'micro')\n",
    "recall_classifier_3 = recall_score(metrics_test_labels, predicted_labels_3, average = 'micro')\n",
    "\n",
    "print(\"F1 score for classifier 3 (linear kernel):\", f1_classifier_3)\n",
    "print(\"Precision score for classifier 3 (linear kernel):\", precision_classifier_3)\n",
    "print(\"Recall score for classifier 3 (linear kernel):\", recall_classifier_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9958689400996315, 0.9958689400996315, 0.9958689400996315, 0.9958689400996315, 0.9958689400996315]\n",
      "[0.9955854359888219, 0.9953931048448337, 0.9959500506243671, 0.997165131112686, 0.9963555375582102]\n"
     ]
    }
   ],
   "source": [
    "#trying different test-train ratios\n",
    "\n",
    "splits = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "classifier_split_test = SVC()\n",
    "for i in range(len(splits)):\n",
    "    train_data_split, test_data_split, train_labels_split, test_labels_split = train_test_split(training_data, labels, train_size = splits[i], random_state = 26)\n",
    "    classifier_split_test.fit(train_data_split, train_labels_split)\n",
    "    predictions = classifier_split_test.predict(metrics_test_data)\n",
    "    f1_scores.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "    accuracy_scores.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "print(f1_scores)\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 41, 49, 63, 42, 16, 36, 9, 66, 90]\n"
     ]
    }
   ],
   "source": [
    "#generating 10 random numbers for different random states\n",
    "import random\n",
    "\n",
    "randstate = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    x = random.randint(1,100)\n",
    "    randstate.append(x)\n",
    "print(randstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating all lists for success metrics\n",
    "#creating empty lists for each number in splits(50 = 50%)\n",
    "f1_scores_50 = []\n",
    "f1_scores_60 = []\n",
    "f1_scores_70 = []\n",
    "f1_scores_80 = []\n",
    "f1_scores_90 = []\n",
    "\n",
    "accuracy_scores_50 = []\n",
    "accuracy_scores_60 = []\n",
    "accuracy_scores_70 = []\n",
    "accuracy_scores_80 = []\n",
    "accuracy_scores_90 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the combinations of random_states and different test-train splits\n",
    "#creating empty lists for each number in splits(50 = 50%)\n",
    "\n",
    "#looping through every instance in splits for every instance in randstate, giving arrays of\n",
    "#the f1_score for every combination of random state and train-test split\n",
    "for rs in range(len(randstate)):\n",
    "    for i in range(len(splits)):\n",
    "        train_data_split, test_data_split, train_labels_split, test_labels_split = train_test_split(training_data, labels, train_size = splits[i], random_state = randstate[rs])\n",
    "        classifier_split_test.fit(train_data_split, train_labels_split)\n",
    "        predictions = classifier_split_test.predict(metrics_test_data)\n",
    "        if splits[i] == 0.5:\n",
    "            f1_scores_50.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "            accuracy_scores_50.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "        elif splits[i] == 0.6:\n",
    "            f1_scores_60.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "            accuracy_scores_60.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "        elif splits[i] == 0.7:\n",
    "            f1_scores_70.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "            accuracy_scores_70.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "        elif splits[i] == 0.8:\n",
    "            f1_scores_80.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "            accuracy_scores_80.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "        elif splits[i] == 0.9:\n",
    "            f1_scores_90.append(f1_score(metrics_test_labels, predictions, average = 'micro'))\n",
    "            accuracy_scores_90.append(classifier_split_test.score(test_data_split, test_labels_split))\n",
    "            \n",
    "#all f1 scores were the same regardless of random state and train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958689400996315\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#calculating the means and standard deviations for the f1 scores.\n",
    "import statistics\n",
    "\n",
    "avg_f1_score_50 = statistics.mean(f1_scores_50)\n",
    "avg_f1_score_60 = statistics.mean(f1_scores_60)\n",
    "avg_f1_score_70 = statistics.mean(f1_scores_70)\n",
    "avg_f1_score_80 = statistics.mean(f1_scores_80)\n",
    "avg_f1_score_90 = statistics.mean(f1_scores_90)\n",
    "\n",
    "print(avg_f1_score_50)\n",
    "\n",
    "std_dev_f1_50 = statistics.stdev(f1_scores_50, avg_f1_score_50)\n",
    "std_dev_f1_60 = statistics.stdev(f1_scores_60, avg_f1_score_60)\n",
    "std_dev_f1_70 = statistics.stdev(f1_scores_70, avg_f1_score_70)\n",
    "std_dev_f1_80 = statistics.stdev(f1_scores_80, avg_f1_score_80)\n",
    "std_dev_f1_90 = statistics.stdev(f1_scores_90, avg_f1_score_90)\n",
    "\n",
    "print(std_dev_f1_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957919889838402\n",
      "0.00018717185365466367\n"
     ]
    }
   ],
   "source": [
    "#calculating mean and standard deviation for accuracy\n",
    "\n",
    "avg_accuracy_50 = statistics.mean(accuracy_scores_50)\n",
    "avg_accuracy_60 = statistics.mean(accuracy_scores_60)\n",
    "avg_accuracy_70 = statistics.mean(accuracy_scores_70)\n",
    "avg_accuracy_80 = statistics.mean(accuracy_scores_80)\n",
    "avg_accuracy_90 = statistics.mean(accuracy_scores_90)\n",
    "\n",
    "print(avg_accuracy_50)\n",
    "\n",
    "std_dev_accuracy_50 = statistics.stdev(accuracy_scores_50, avg_accuracy_50)\n",
    "std_dev_accuracy_60 = statistics.stdev(accuracy_scores_60, avg_accuracy_60)\n",
    "std_dev_accuracy_70 = statistics.stdev(accuracy_scores_70, avg_accuracy_70)\n",
    "std_dev_accuracy_80 = statistics.stdev(accuracy_scores_80, avg_accuracy_80)\n",
    "std_dev_accuracy_90 = statistics.stdev(accuracy_scores_90, avg_accuracy_90)\n",
    "\n",
    "print(std_dev_accuracy_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphically displaying means and standard deviations for f1_score.\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('agg')\n",
    "\n",
    "plot_f1 = [f1_scores_50,f1_scores_60,f1_scores_70,f1_scores_80,f1_scores_90]\n",
    "\n",
    "plt_1, ax1 = plt.subplots()\n",
    "ax1.set_title('F1 Score vs Proportion of data used for training and different random states')\n",
    "ax1.set_ylabel('F1 Score')\n",
    "ax1.set_xlabel('Proportion of data used for training')\n",
    "ax1.set_xticklabels(['50%', '60%', '70%', '80%', '90%'])\n",
    "ax1.get_xaxis().tick_bottom()\n",
    "ax1.get_yaxis().tick_left()\n",
    "ax1.boxplot(plot_f1)\n",
    "\n",
    "\n",
    "plt_1.savefig('f1_boxplot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphically displaying means and standard deviations for f1_score.\n",
    "\n",
    "plot_acc = [accuracy_scores_50,accuracy_scores_60,accuracy_scores_70,accuracy_scores_80,accuracy_scores_90]\n",
    "\n",
    "plt_2, ax2 = plt.subplots()\n",
    "ax2.set_title('Classification Accuracy vs Proportion of data used for training and different random states')\n",
    "ax2.set_ylabel('Classification Accuracy')\n",
    "ax2.set_xlabel('Proportion of data used for training')\n",
    "ax2.set_xticklabels(['50%', '60%', '70%', '80%', '90%'])\n",
    "ax2.get_xaxis().tick_bottom()\n",
    "ax2.get_yaxis().tick_left()\n",
    "ax2.boxplot(plot_acc)\n",
    "\n",
    "\n",
    "plt_2.savefig('accuracy_boxplot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "training time: 2.585569143295288 seconds\n",
      "0.9957474813952311\n",
      "test duration: 1.1491458415985107 seconds\n"
     ]
    }
   ],
   "source": [
    "#building a \"light\" model (rbf kernel function) - training and testing the model\n",
    "print(len(light_data.columns))\n",
    "light_classifier = SVC()\n",
    "light_train_start = time.time()\n",
    "light_classifier.fit(light_train_data, light_train_labels)\n",
    "light_train_time = time.time() - light_train_start\n",
    "print(\"training time:\", light_train_time, \"seconds\")\n",
    "\n",
    "light_test_start = time.time()\n",
    "print(light_classifier.score(light_test_data, light_test_labels))\n",
    "light_test_time = time.time() - light_test_start\n",
    "print(\"test duration:\", light_test_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 1.4795880317687988 seconds\n",
      "F1 score for light classifier (rbf kernel): 0.9958689400996315\n",
      "Precision score for light classifier (rbf kernel): 0.9958689400996315\n",
      "Recall score for light classifier (rbf kernel): 0.9958689400996315\n"
     ]
    }
   ],
   "source": [
    "#building a \"light\" model (rbf kernel function) - testing the models f1 score\n",
    "filler_train, light_metrics_test_data, filler_labels, light_metrics_test_labels = train_test_split(light_data, light_data_labels, train_size = 0.5, random_state = 46)\n",
    "#getting these metrics for the classifer (rbf)\n",
    "start_light_predict = time.time()\n",
    "predicted_labels_light = light_classifier.predict(light_metrics_test_data)\n",
    "run_time_light_predict = time.time() - start_light_predict\n",
    "print(\"Prediction time:\", run_time_light_predict, \"seconds\")\n",
    "\n",
    "f1_classifier_light = f1_score(light_metrics_test_labels, predicted_labels_light, average = 'micro')\n",
    "precision_classifier_light = precision_score(light_metrics_test_labels, predicted_labels_light, average = 'micro')\n",
    "recall_classifier_light = recall_score(light_metrics_test_labels, predicted_labels_light, average = 'micro')\n",
    "\n",
    "print(\"F1 score for light classifier (rbf kernel):\", f1_classifier_light)\n",
    "print(\"Precision score for light classifier (rbf kernel):\", precision_classifier_light)\n",
    "print(\"Recall score for light classifier (rbf kernel):\", recall_classifier_light)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 912.5254321098328\n",
      "0.9957474813952311\n",
      "test duration: 0.35927486419677734\n"
     ]
    }
   ],
   "source": [
    "#building a \"light\" model (poly kernel function) - training and testing the model\n",
    "light_classifier_poly = SVC(kernel = 'poly')\n",
    "light_train_start_poly = time.time()\n",
    "light_classifier_poly.fit(light_train_data, light_train_labels)\n",
    "light_train_time_poly = time.time() - light_train_start_poly\n",
    "print(\"training time:\", light_train_time_poly)\n",
    "\n",
    "light_test_start_poly = time.time()\n",
    "print(light_classifier_poly.score(light_test_data, light_test_labels))\n",
    "light_test_time_poly = time.time() - light_test_start_poly\n",
    "print(\"test duration:\", light_test_time_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.46828508377075195 seconds\n",
      "F1 score for light classifier (poly kernel): 0.9958689400996315\n",
      "Precision score for light classifier (poly kernel): 0.9958689400996315\n",
      "Recall score for light classifier (poly kernel): 0.9958689400996315\n"
     ]
    }
   ],
   "source": [
    "#building a \"light\" model (poly kernel function) - testing the models f1 score\n",
    "#getting these metrics for the classifer (poly)\n",
    "start_light_predict_poly = time.time()\n",
    "predicted_labels_light_poly = light_classifier_poly.predict(light_metrics_test_data)\n",
    "run_time_light_predict_poly = time.time() - start_light_predict_poly\n",
    "print(\"Prediction time:\", run_time_light_predict_poly, \"seconds\")\n",
    "\n",
    "f1_classifier_light_poly = f1_score(light_metrics_test_labels, predicted_labels_light_poly, average = 'micro')\n",
    "precision_classifier_light_poly = precision_score(light_metrics_test_labels, predicted_labels_light_poly, average = 'micro')\n",
    "recall_classifier_light_poly = recall_score(light_metrics_test_labels, predicted_labels_light_poly, average = 'micro')\n",
    "\n",
    "print(\"F1 score for light classifier (poly kernel):\", f1_classifier_light_poly)\n",
    "print(\"Precision score for light classifier (poly kernel):\", precision_classifier_light_poly)\n",
    "print(\"Recall score for light classifier (poly kernel):\", recall_classifier_light_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=62, shuffle=True)\n",
      "Using k-fold cross validation:\n",
      "Accuracy: 0.994229016907968\n",
      "F1 Score: 0.994229016907968\n",
      "Accuracy: 0.9961526779386454\n",
      "F1 Score: 0.9961526779386454\n",
      "Accuracy: 0.9961522883758607\n",
      "F1 Score: 0.9961522883758607\n",
      "Accuracy: 0.9968610773592548\n",
      "F1 Score: 0.9968610773592548\n",
      "Accuracy: 0.9955447549615228\n",
      "F1 Score: 0.9955447549615228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#implementing K cross-fold validation as a method of splitting data for training and validation.\n",
    "#utilising the light data as it provides comparible performance and reduces training and prediction times.\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = 62, shuffle = True)\n",
    "print(kf)\n",
    "\n",
    "kfold_data = light_data.copy()\n",
    "kfold_labels = light_data_labels.copy()\n",
    "kfold_data = kfold_data.to_numpy()\n",
    "kfold_labels  = kfold_labels.to_numpy()\n",
    "#testing effectiveness with kfold cross validation - rbf kernel\n",
    "kfold_classifier = SVC()\n",
    "\n",
    "kfold_f1score = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "\n",
    "for train_index, test_index in kf.split(kfold_data):\n",
    "     data_train, data_test = kfold_data[train_index], kfold_data[test_index]\n",
    "     labels_train, labels_test = kfold_labels[train_index], kfold_labels[test_index]\n",
    "     kfold_classifier.fit(data_train, labels_train)\n",
    "     accuracy_score = kfold_classifier.score(data_test, labels_test)\n",
    "     print(\"Accuracy:\", accuracy_score)\n",
    "     kfold_f1score.append(f1_score(labels_test, kfold_classifier.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score:\", f1_score(labels_test, kfold_classifier.predict(data_test), average = 'micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score - rbf kernel: 0.9957879631086504\n",
      "Standard deviation in F1 score - rbf kernel: 0.0009882797506080238\n"
     ]
    }
   ],
   "source": [
    "#calculating mean F1 score and standard deviation for KFold classifier - rbf kernel\n",
    "mean_f1_kfold = statistics.mean(kfold_f1score)\n",
    "\n",
    "stddev_f1_kfold = statistics.stdev(kfold_f1score, mean_f1_kfold)\n",
    "\n",
    "print(\"Mean F1 Score - rbf kernel:\", mean_f1_kfold)\n",
    "print(\"Standard deviation in F1 score - rbf kernel:\", stddev_f1_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k-fold cross validation:\n",
      "Accuracy - poly kernel: 0.994229016907968\n",
      "F1 Score - poly kernel: 0.994229016907968\n",
      "Accuracy - poly kernel: 0.9961526779386454\n",
      "F1 Score - poly kernel: 0.9961526779386454\n",
      "Accuracy - poly kernel: 0.9961522883758607\n",
      "F1 Score - poly kernel: 0.9961522883758607\n",
      "Accuracy - poly kernel: 0.9968610773592548\n",
      "F1 Score - poly kernel: 0.9968610773592548\n",
      "Accuracy - poly kernel: 0.9955447549615228\n",
      "F1 Score - poly kernel: 0.9955447549615228\n"
     ]
    }
   ],
   "source": [
    "#using different kernel functions to test effectiveness - poly kernel\n",
    "kfold_classifier_poly = SVC(kernel = 'poly')\n",
    "\n",
    "kfold_f1score_poly = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "\n",
    "for train_index, test_index in kf.split(kfold_data):\n",
    "     data_train, data_test = kfold_data[train_index], kfold_data[test_index]\n",
    "     labels_train, labels_test = kfold_labels[train_index], kfold_labels[test_index]\n",
    "     kfold_classifier_poly.fit(data_train, labels_train)\n",
    "     accuracy_score = kfold_classifier_poly.score(data_test, labels_test)\n",
    "     print(\"Accuracy - poly kernel:\", accuracy_score)\n",
    "     kfold_f1score_poly.append(f1_score(labels_test, kfold_classifier_poly.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score - poly kernel:\", f1_score(labels_test, kfold_classifier_poly.predict(data_test), average = 'micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amnt', 'term', 'int_rate', 'grade', 'emp_length',\n",
      "       'home_ownership', 'annual_inc', 'purpose', 'dti', 'delinq_2yrs',\n",
      "       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',\n",
      "       'total_acc', 'out_prncp', 'total_pymnt', 'recoveries',\n",
      "       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'application_type',\n",
      "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
      "       'open_il_6m', 'open_il_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
      "       'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens',\n",
      "       'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'loan_status', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_NONE', 'home_ownership_OWN',\n",
      "       'home_ownership_RENT', 'grade_A', 'grade_B', 'grade_C', 'grade_D',\n",
      "       'grade_E', 'grade_F', 'grade_G', 'application_type_ ',\n",
      "       'application_type_DIRECT_PAY', 'application_type_INDIVIDUAL',\n",
      "       'application_type_JOINT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score - poly kernel: 0.9957879631086504\n",
      "Standard deviation in F1 score - poly kernel: 0.0009882797506080238\n"
     ]
    }
   ],
   "source": [
    "#calculating mean F1 score and standard deviation for KFold classifier - poly kernel\n",
    "mean_f1_kfold_poly = statistics.mean(kfold_f1score_poly)\n",
    "\n",
    "stddev_f1_kfold_poly = statistics.stdev(kfold_f1score_poly, mean_f1_kfold_poly)\n",
    "\n",
    "print(\"Mean F1 Score - poly kernel:\", mean_f1_kfold_poly)\n",
    "print(\"Standard deviation in F1 score - poly kernel:\", stddev_f1_kfold_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k-fold cross validation:\n"
     ]
    }
   ],
   "source": [
    "#using different kernel functions to test effectiveness - linear kernel\n",
    "kfold_classifier_linear = SVC(kernel = 'linear')\n",
    "\n",
    "kfold_f1score_linear = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "\n",
    "for train_index, test_index in kf.split(kfold_data):\n",
    "     data_train, data_test = kfold_data[train_index], kfold_data[test_index]\n",
    "     labels_train, labels_test = kfold_labels[train_index], kfold_labels[test_index]\n",
    "     kfold_classifier_linear.fit(data_train, labels_train)\n",
    "     accuracy_score = kfold_classifier_linear.score(data_test, labels_test)\n",
    "     print(\"Accuracy - linear kernel:\", accuracy_score)\n",
    "     kfold_f1score_linear.append(f1_score(labels_test, kfold_classifier_linear.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score - linear kernel:\", f1_score(labels_test, kfold_classifier_linear.predict(data_test), average = 'micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score - linear kernel: 0.9955652131587092\n",
      "Standard deviation in F1 score - linear kernel: 0.001161794294815394\n"
     ]
    }
   ],
   "source": [
    "#calculating mean F1 score and standard deviation for KFold classifier - linear kernel\n",
    "mean_f1_kfold_linear = statistics.mean(kfold_f1score_linear)\n",
    "\n",
    "stddev_f1_kfold_linear = statistics.stdev(kfold_f1score_linear, mean_f1_kfold_linear)\n",
    "\n",
    "print(\"Mean F1 Score - linear kernel:\", mean_f1_kfold_linear)\n",
    "print(\"Standard deviation in F1 score - linear kernel:\", stddev_f1_kfold_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k-fold cross validation:\n",
      "Accuracy - linear kernel: 0.994229016907968\n",
      "F1 Score - linear kernel: 0.994229016907968\n",
      "Accuracy - linear kernel: 0.9961526779386454\n",
      "F1 Score - linear kernel: 0.9961526779386454\n",
      "Accuracy - linear kernel: 0.9961522883758607\n",
      "F1 Score - linear kernel: 0.9961522883758607\n",
      "Accuracy - linear kernel: 0.9968610773592548\n",
      "F1 Score - linear kernel: 0.9968610773592548\n",
      "Accuracy - linear kernel: 0.9955447549615228\n",
      "F1 Score - linear kernel: 0.9955447549615228\n"
     ]
    }
   ],
   "source": [
    "#formatting training data and lables\n",
    "training_data = training_data.to_numpy()\n",
    "labels = labels.to_numpy()\n",
    "\n",
    "#Performing K-fold cross validation on K-fold cross validation on Classifier 1- rbf kernel\n",
    "#Using \"full\" training data\n",
    "\n",
    "kfold_f1score_rbffull = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "\n",
    "for train_index, test_index in kf.split(training_data):\n",
    "     data_train, data_test = training_data[train_index], training_data[test_index]\n",
    "     labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "     classifier_1.fit(data_train, labels_train)\n",
    "     accuracy_score = classifier_1.score(data_test, labels_test)\n",
    "     print(\"Accuracy - linear kernel:\", accuracy_score)\n",
    "     kfold_f1score_rbffull.append(f1_score(labels_test, classifier_1.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score - linear kernel:\", f1_score(labels_test, classifier_1.predict(data_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k-fold cross validation:\n",
      "Accuracy - linear kernel: 0.994229016907968\n",
      "F1 Score - linear kernel: 0.994229016907968\n",
      "Accuracy - linear kernel: 0.9961526779386454\n",
      "F1 Score - linear kernel: 0.9961526779386454\n",
      "Accuracy - linear kernel: 0.9961522883758607\n",
      "F1 Score - linear kernel: 0.9961522883758607\n",
      "Accuracy - linear kernel: 0.9968610773592548\n",
      "F1 Score - linear kernel: 0.9968610773592548\n",
      "Accuracy - linear kernel: 0.9955447549615228\n",
      "F1 Score - linear kernel: 0.9955447549615228\n"
     ]
    }
   ],
   "source": [
    "#Performing K-fold cross validation on K-fold cross validation on Classifier 2- poly kernel\n",
    "#Using \"full\" training data\n",
    "\n",
    "kfold_f1score_polyfull = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "\n",
    "for train_index, test_index in kf.split(training_data):\n",
    "     data_train, data_test = training_data[train_index], training_data[test_index]\n",
    "     labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "     classifier_2.fit(data_train, labels_train)\n",
    "     accuracy_score = classifier_2.score(data_test, labels_test)\n",
    "     print(\"Accuracy - linear kernel:\", accuracy_score)\n",
    "     kfold_f1score_polyfull.append(f1_score(labels_test, classifier_2.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score - linear kernel:\", f1_score(labels_test, classifier_2.predict(data_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing K-fold cross validation on K-fold cross validation on Classifier 3- linear kernel\n",
    "#Using \"full\" training data\n",
    "\n",
    "kfold_f1score_linearfull = []\n",
    "print(\"Using k-fold cross validation:\")\n",
    "for train_index, test_index in kf.split(training_data):\n",
    "     data_train, data_test = training_data[train_index], training_data[test_index]\n",
    "     labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "     classifier_3.fit(data_train, labels_train)\n",
    "     accuracy_score = classifier_3.score(data_test, labels_test)\n",
    "     print(\"Accuracy - linear kernel:\", accuracy_score)\n",
    "     kfold_f1score_linearfull.append(f1_score(labels_test, classifier_3.predict(data_test), average = 'micro'))\n",
    "     print(\"F1 Score - linear kernel:\", f1_score(labels_test, classifier_3.predict(data_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphically displaying means and standard deviations for each of the classifiers tested using K-fold cross validation\n",
    "\n",
    "K_fold_F1 = [kfold_f1score_rbffull,kfold_f1score,kfold_f1score_polyfull,kfold_f1score_poly]\n",
    "\n",
    "plt_3, ax3 = plt.subplots()\n",
    "ax3.set_title('F1 Score vs Dataset and kernel function used')\n",
    "ax3.set_ylabel('F1 scores')\n",
    "ax3.set_xlabel('Dataset and kernel function')\n",
    "ax3.set_xticklabels(['full, rbf', 'light, rbf', 'full, poly', 'light, poly'])\n",
    "ax3.get_xaxis().tick_bottom()\n",
    "ax3.get_yaxis().tick_left()\n",
    "ax3.boxplot(K_fold_F1)\n",
    "\n",
    "\n",
    "plt_3.savefig('F1_Scores_Kfold.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amnt', 'term', 'int_rate', 'emp_length', 'annual_inc', 'dti',\n",
      "       'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'out_prncp', 'total_pymnt', 'recoveries',\n",
      "       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'acc_now_delinq',\n",
      "       'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m',\n",
      "       'open_il_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
      "       'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens',\n",
      "       'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_NONE', 'home_ownership_OWN',\n",
      "       'home_ownership_RENT', 'grade_A', 'grade_B', 'grade_C', 'grade_D',\n",
      "       'grade_E', 'grade_F', 'grade_G', 'application_type_ ',\n",
      "       'application_type_DIRECT_PAY', 'application_type_INDIVIDUAL',\n",
      "       'application_type_JOINT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#VISUALISATION - KMeans clustering on the dataset, 4 clusters will be used to begin with (one for each class)\n",
    "#as it is important to see whether there can be common features discovered between the \n",
    "#data in each cluster.\n",
    "#from sklearn.cluster import KMeans\n",
    "#kmeans = KMeans(n_clusters = 2)\n",
    "\n",
    "#kmeans_data = training_data.copy()\n",
    "#print(kmeans_data.columns)\n",
    "#kmeans_data = kmeans_data.to_numpy()\n",
    "#train the model\n",
    "#kmeans.fit(kmeans_data)\n",
    "#y_kmeans = kmeans.predict(kmeans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting the KMeans data\n",
    "#plt.title(\"Loan amount vs. FEATURE\")\n",
    "#plt.ylabel(\"Loan amount\")\n",
    "#plt.xlabel(\"FEATURE\")\n",
    "#THESE NEED TO BE CHANGED TO BE ACTUALLY VALUABLE\n",
    "#plotting data\n",
    "#plt.scatter(kmeans_data[:,1],kmeans_data[:,0], c=y_kmeans, s=50, cmap = 'viridis')\n",
    "#plot the centroids on the graph\n",
    "#centroids = kmeans.cluster_centers_\n",
    "#plt.scatter(centroids[:,1],centroids[:,0], c='black', s=200, alpha=0.5)\n",
    "#plt.savefig('test1.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
